{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qE19rpDNCG7l",
        "fNnM4UWXBiTH",
        "eVMj6L-vGf-f",
        "Kaap2ZdpBnrG",
        "E4tC3dt6Bs0L",
        "1BFovqshi0o2",
        "tVDQ-ITRqaTP",
        "61Afo_rkYovO",
        "8LGT0o_547Ib",
        "P6hLAIyJXoUJ",
        "NPA1EgVz5XzC",
        "s9H5us_pB6jq",
        "Ttzt3hS9lXn4",
        "2-p1g27gdk1o",
        "W7dJPNkZcgrn",
        "iIX9tWvzflhn",
        "PLwKjwOj1MT_",
        "4u62muSh-yxb",
        "ESiSSkt6ceBE",
        "TdHj6A1YEygK",
        "_KOeR_jSE25Y",
        "EeV7mQVBE9vi",
        "Hg8e1S5Rj903",
        "hPP96Bae8PBe",
        "OuT5cWvF8R2-",
        "aHfI338F8YHs",
        "QPuejHSYLaZG",
        "fgKqCC0tLgQI",
        "9iqHoiY2iUw0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#libraries"
      ],
      "metadata": {
        "id": "qE19rpDNCG7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn import tree\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ],
      "metadata": {
        "id": "VYJzi67bCJfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Numpy"
      ],
      "metadata": {
        "id": "fNnM4UWXBiTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(np)"
      ],
      "metadata": {
        "id": "uiRPdrCjRlrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([1,2,3])"
      ],
      "metadata": {
        "id": "0nkQONJgQ33N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros(7)\n",
        "np.zeros((5,7))\n",
        "np.zeros((2,5,7))\n",
        "np.zeros((3,2,5,7), dtype=\"int\")"
      ],
      "metadata": {
        "id": "BnbOzA1xSKbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones(7)\n",
        "np.ones((5,7))\n",
        "np.ones((2,5,7))\n",
        "np.ones((3,2,5,7), dtype=\"int\")"
      ],
      "metadata": {
        "id": "yYMWLe3kTODR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones(7) * 6"
      ],
      "metadata": {
        "id": "ESdNZZUVUQC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.full(7,3)\n",
        "np.full((5,7), 3)\n",
        "np.full((2,5,7), 3)\n",
        "np.full((3,2,5,7), 3, dtype=\"int\")"
      ],
      "metadata": {
        "id": "B-RIsvuhUdzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(0,10)"
      ],
      "metadata": {
        "id": "kdC5o3fPU-8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.linspace(0,100,6)"
      ],
      "metadata": {
        "id": "3yFanFskVzlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.rand(5)"
      ],
      "metadata": {
        "id": "w5mcNvUZXLS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.rand(5,7)\n",
        "np.random.rand(5,7,8)"
      ],
      "metadata": {
        "id": "fDplTNeFYjTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.randn(5)"
      ],
      "metadata": {
        "id": "x_h9bIpKZxQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.randint(1,100,(5,2))"
      ],
      "metadata": {
        "id": "WN8QnwfbbRlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.normal(20, 3, (4,3))"
      ],
      "metadata": {
        "id": "7OQrAhOGZyQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "x = np.random.normal(8, 0.3, 50)\n",
        "y = np.random.normal(8, 0.3, 50)\n",
        "plt.axis([0,10,0,10])\n",
        "plt.scatter(x,y)\n",
        "plt.scatter([8],[8], color=\"red\")"
      ],
      "metadata": {
        "id": "oON4URBFa2tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = np.random.randint(10,50, (5,4))"
      ],
      "metadata": {
        "id": "43lnHyVJpG9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim"
      ],
      "metadata": {
        "id": "rjDBsGHCpOf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.shape"
      ],
      "metadata": {
        "id": "xSKGpE7upRQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.size"
      ],
      "metadata": {
        "id": "M9kA5TNepkwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.dtype"
      ],
      "metadata": {
        "id": "PfISfRlmpxiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = np.arange(1,16)\n",
        "example"
      ],
      "metadata": {
        "id": "fFv56n2Vp6FI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example.reshape((3,5))"
      ],
      "metadata": {
        "id": "JMMtROhTsgG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.max()"
      ],
      "metadata": {
        "id": "yJyPDkdhssZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.argmax()"
      ],
      "metadata": {
        "id": "XZE-e8Z6t_CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.min()"
      ],
      "metadata": {
        "id": "x_doa6EOuMKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.argmin()"
      ],
      "metadata": {
        "id": "w16eucViumZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_array  = np.random.randint(1,7, (3,2))\n",
        "second_array = np.random.randint(1,7, (3,2))\n",
        "\n",
        "third_array  = np.concatenate([first_array, second_array])\n",
        "fourth_array = np.concatenate([first_array, second_array], axis = 1)"
      ],
      "metadata": {
        "id": "cff1F6rOunQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.random.randint(1,20,7)\n",
        "array"
      ],
      "metadata": {
        "id": "FyaFmP3svGTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_array = np.sort(array)\n",
        "new_array"
      ],
      "metadata": {
        "id": "_Qs0z7CexBo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array = np.random.randint(1,100,12)\n",
        "array"
      ],
      "metadata": {
        "id": "ATPTlS6zxIna"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array[array > 50]"
      ],
      "metadata": {
        "id": "eFY0sjuwBt7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "condition = array <= 40\n",
        "array[condition]"
      ],
      "metadata": {
        "id": "fOcC5u0xB2yS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array * 2\n",
        "array - 2\n",
        "array + 2\n",
        "array / 2\n",
        "array * array"
      ],
      "metadata": {
        "id": "yDw1cwQVCY-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(array)"
      ],
      "metadata": {
        "id": "jDQCc4cwCxzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.median(array)"
      ],
      "metadata": {
        "id": "oyWS6LY6DWRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.std(array)"
      ],
      "metadata": {
        "id": "KvMSjYfyDlpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas"
      ],
      "metadata": {
        "id": "eVMj6L-vGf-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series([10,20,30,40,50,60])"
      ],
      "metadata": {
        "id": "Geb_sSKTGlak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_example = [5,10,56,98,45]\n",
        "pd.DataFrame(columns=['Values'], data = list_example)"
      ],
      "metadata": {
        "id": "lVat_NL5IMSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vals = np.arange(1,13).reshape(3,4)\n",
        "pd.DataFrame(data = vals, columns = ['a','b','c','d'])"
      ],
      "metadata": {
        "id": "4M8bK2fuJCo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data file name.csv\")"
      ],
      "metadata": {
        "id": "a7a7CB2qKCLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"data file name.csv\")"
      ],
      "metadata": {
        "id": "nTQGcDP0LNSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n",
        "# df.head(5)\n",
        "# df.head(10)"
      ],
      "metadata": {
        "id": "SjBlD3DJLVRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "dpOsI7SULnp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.ndim"
      ],
      "metadata": {
        "id": "RV_zLLtJLsVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['column_1']"
      ],
      "metadata": {
        "id": "5sbfcACDGL40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.column_1"
      ],
      "metadata": {
        "id": "xmPXJx1tGgPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['column_1'].values"
      ],
      "metadata": {
        "id": "7cmbVvAbGgNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['column_1','column_2']]"
      ],
      "metadata": {
        "id": "iBcsvXSzGgKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['column_1':'column_5']"
      ],
      "metadata": {
        "id": "OaoCsye3GgIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select first row using loc\n",
        "print(df.loc['index_1_name'])\n",
        "\n",
        "# select first row using iloc\n",
        "print(df.iloc[0])"
      ],
      "metadata": {
        "id": "L1V75_tRGgGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select first row to tenth row using loc\n",
        "print(df.loc['index_1_name':'index_10_name'])\n",
        "\n",
        "# select first row to tenth row using iloc\n",
        "print(df.iloc[0:10])"
      ],
      "metadata": {
        "id": "UvhQLG1FGgDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_slice = df.iloc[:, 1:6]"
      ],
      "metadata": {
        "id": "jT13qiW_GgAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_slice = df.loc[:, 'column_1': 'column_5']"
      ],
      "metadata": {
        "id": "Y9ykAZtSGf-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add a new column\n",
        "df['col_5'] = [65, 8, 94, 23, 87]"
      ],
      "metadata": {
        "id": "lXIfxUJ2Gf3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df ['col_6'] = df['col_1'] + df['col_5']"
      ],
      "metadata": {
        "id": "TMa0Va9jPBnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop(['col_1','col_2','col_3'], axis = 1)\n"
      ],
      "metadata": {
        "id": "eFYpAxXOP21G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_df = df.drop(index=range(1, 5133))\n"
      ],
      "metadata": {
        "id": "wH18ilTdQGaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "new_df = df.drop([1, 65, 88])\n"
      ],
      "metadata": {
        "id": "9eV-SKyTR46l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df.drop([1, 65, 88], inplace=True)\n"
      ],
      "metadata": {
        "id": "VSHPyL9BR44U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = df.drop([1, 65, 88])\n"
      ],
      "metadata": {
        "id": "eyhMagSyR416"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "bUu7MFNPe-wS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"titanic\")"
      ],
      "metadata": {
        "id": "KdAENm_3R4xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "V3011ythfMnZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(df.isnull().sum() * 100) / len(df)"
      ],
      "metadata": {
        "id": "NTLuIfnwfw-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "len(df[df.iloc[:, 11].notna()])\n"
      ],
      "metadata": {
        "id": "oxIgcXPfgh4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df.iloc[:, 11].notnull()])"
      ],
      "metadata": {
        "id": "7ycTqMpOkFE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "iBezgnB8hHTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "objDpi2akZec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.fillna(1000)"
      ],
      "metadata": {
        "id": "En3761tHmjUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical and numerical columns\n",
        "categorical_cols = df.select_dtypes(exclude=np.number).columns\n",
        "numerical_cols = df.select_dtypes(include=np.number).columns\n",
        "\n",
        "# Fill null values in categorical columns with the mode\n",
        "for col in categorical_cols:\n",
        "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
        "\n",
        "# Fill null values in numerical columns with the mean\n",
        "for col in numerical_cols:\n",
        "    df[col].fillna(df[col].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "jfI6vcepnICW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "HNTM87UQoVls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")"
      ],
      "metadata": {
        "id": "hga_oo7YfhBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "uhN9AFKjhsLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "8AzkxLjXfmtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "eandhBsGfoDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "df[num_cols].mean()"
      ],
      "metadata": {
        "id": "uMnnKiBJfo5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "df[num_cols].std()"
      ],
      "metadata": {
        "id": "ITZMlpSNgXFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "df[num_cols].median()"
      ],
      "metadata": {
        "id": "bp5ggr9ohGOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cylinders'].value_counts()"
      ],
      "metadata": {
        "id": "v_InYovchY4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cylinders'].unique()"
      ],
      "metadata": {
        "id": "PLpW1zhzhvkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['origin'].unique()"
      ],
      "metadata": {
        "id": "aIomQJeNiVE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('origin')['cylinders'].mean()"
      ],
      "metadata": {
        "id": "EIIMBIwtigEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.crosstab(df['origin'], df['cylinders'])"
      ],
      "metadata": {
        "id": "FcwDJnQIjNs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=np.number).columns\n",
        "df.groupby('origin')[num_cols].mean()"
      ],
      "metadata": {
        "id": "hYKvRGzvjkZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "origin = {'usa': 0, 'japan': 1, 'europe': 2}\n",
        "df['origin'] = df['origin'].map(origin)"
      ],
      "metadata": {
        "id": "ggHOGsg4qFjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use factorize to transform the categorical column to numerical\n",
        "df['origin'], class_mapping = pd.factorize(df['origin'])\n",
        "\n",
        "print(\"Class mapping:\", class_mapping.tolist())\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "sZn8aQd7rXuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalizer(x):\n",
        "    return (x - x.min()) / (x.max() - x.min())\n",
        "\n",
        "df.iloc[:, 0:8] = df.iloc[:, 0:8].transform(normalizer)"
      ],
      "metadata": {
        "id": "-pwEL4vJoLkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[:, 0:8] = df.iloc[:, 0:8].transform(lambda a: np.sin(a))"
      ],
      "metadata": {
        "id": "5NSO7DVTdln9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "EJWlq8KArPrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Matplotlib"
      ],
      "metadata": {
        "id": "Kaap2ZdpBnrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1, 10, 0.3)\n",
        "y_points = np.sin(x_points)\n",
        "\n",
        "plt.plot(x_points, y_points,color = 'red')"
      ],
      "metadata": {
        "id": "B2hHdBS3jsc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('x points')\n",
        "plt.ylabel('y points')\n",
        "\n",
        "# plt.plot(x_points, y_points,\".\", color = 'red')\n",
        "# plt.plot(x_points, y_points, 'go--', linewidth=2, markersize=8)\n",
        "plt.plot(x_points, y_points, 'ro--', linewidth=1.5, markersize=8)\n"
      ],
      "metadata": {
        "id": "uS_JKjmtj9sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1, 10, 0.3)\n",
        "y_points_1 = np.sin(x_points)\n",
        "y_points_2 = np.cos(x_points)\n",
        "\n",
        "plt.plot(x_points, y_points_1, \"ro--\")\n",
        "plt.plot(x_points, y_points_2, \"go--\")"
      ],
      "metadata": {
        "id": "cY69ADiHoQjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1, 10)\n",
        "y_points = (x_points) * 2\n",
        "\n",
        "plt.bar(x_points, y_points)"
      ],
      "metadata": {
        "id": "NoOJC-xpplp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1, 10)\n",
        "y_points = (x_points) * 2\n",
        "\n",
        "plt.barh(x_points, y_points)"
      ],
      "metadata": {
        "id": "qzgityAhqLS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1, 10)\n",
        "y_points = (x_points) * 2\n",
        "\n",
        "plt.step(x_points, y_points)"
      ],
      "metadata": {
        "id": "p3DykxBYrM27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,8))\n",
        "plt.step(x_points, y_points)"
      ],
      "metadata": {
        "id": "enzauYL_rueU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1, 10, 0.3)\n",
        "y_points = np.sin(x_points)\n",
        "\n",
        "Figure, Axes = plt.subplots(nrows = 2, ncols = 2, figsize=(8, 6))  # Set the figure size\n",
        "Axes[0, 0].plot(x_points, y_points, \"bo--\")\n",
        "Axes[0, 1].plot(x_points, y_points, \"ro--\")\n",
        "Axes[1, 1].plot(x_points, y_points, \"yo--\")\n",
        "\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "obr37-UwsqPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(x_points, y_points, \"bo--\", label=\"first\")\n",
        "plt.plot(x_points+2, y_points, \"ro--\", label=\"second\")\n",
        "\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "hd8Hq8PttJ1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_1 = np.random.normal(5, 0.5, 500)\n",
        "y_1 = np.random.normal(8, 0.5, 500)\n",
        "\n",
        "x_2 = np.random.normal(10, 1.2, 500)\n",
        "y_2 = np.random.normal(3, 1.2, 500)\n",
        "\n",
        "\n",
        "plt.scatter(x_1, y_1, color = \"red\")\n",
        "plt.scatter(x_2, y_2, color = \"black\")"
      ],
      "metadata": {
        "id": "1lyuEKFWut5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_points = np.arange(1,10)\n",
        "y_points = x_points * 4\n",
        "\n",
        "plt.axis([0,15,-20,50])\n",
        "plt.plot(x_points, y_points)"
      ],
      "metadata": {
        "id": "YBXF6EgBwE6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(-2 * np.pi, 2 * np.pi, 0.01)\n",
        "y = np.sin(x)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(x, y)\n",
        "\n",
        "ax.set_xticks([-6, 6])\n",
        "ax.set_yticks([-1, 0, 1])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6PbbnI3KvH6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.axhline(0, color='black',linewidth=0.5)\n",
        "plt.axvline(0, color='black',linewidth=0.5)\n",
        "plt.plot()"
      ],
      "metadata": {
        "id": "cE1pPH-pynMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.arange(1, 7)\n",
        "y = np.random.randint(500, 1000, 6)\n",
        "\n",
        "figure, ax = plt.subplots()\n",
        "plot = ax.bar(x, y)\n",
        "\n",
        "for bar in plot:\n",
        "    height = bar.get_height()\n",
        "    ax.text(x = bar.get_x() + bar.get_width() / 2, y = 1.002 * height, s = int(height), ha = 'center', va = 'bottom')"
      ],
      "metadata": {
        "id": "ppKfLitm12-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate data for 'input' 0 with a normal distribution\n",
        "X0 = np.zeros(5000).reshape(5000,1)\n",
        "y0 = np.random.normal(loc=50000, scale=10000, size=5000).reshape(5000,1)\n",
        "\n",
        "# Generate data for 'input' 1 with a normal distribution\n",
        "X1 = np.ones(5000).reshape(5000,1)\n",
        "y1 = np.random.normal(loc=70000, scale=15000, size=5000).reshape(5000,1)\n",
        "\n",
        "# Generate data for 'input' 2 with a normal distribution\n",
        "X2 = np.full((5000, 1), 2)\n",
        "y2 = np.random.normal(loc=90000, scale=20000, size=5000).reshape(5000,1)\n",
        "\n",
        "# Concatenate the data\n",
        "X = np.concatenate([X0, X1, X2], axis=0)\n",
        "y = np.concatenate([y0, y1, y2], axis=0)\n",
        "data = np.concatenate([X, y], axis=1)\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(columns=['input', 'output'], data=data)"
      ],
      "metadata": {
        "id": "JpQjG2ZMT0AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seaborn"
      ],
      "metadata": {
        "id": "E4tC3dt6Bs0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a boxplot\n",
        "sns.boxplot(x='input', y='output', data=df, width=0.2)\n"
      ],
      "metadata": {
        "id": "0t_jngvy3hnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"white\")\n",
        "x = [1, 2, 3, 4, 5, 6]\n",
        "y = [12, 8, 65, 32, 56, 17]\n",
        "plt.axis([0,7, 0,70])\n",
        "plt.plot(x, y)"
      ],
      "metadata": {
        "id": "0e_pYb5BOD5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "XXNADA1HCnBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"whitegrid\")\n",
        "sns.barplot(x = 'origin', y = 'mpg', hue = \"cylinders\", data = df)"
      ],
      "metadata": {
        "id": "pYkVgyKgDwqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "sns.distplot(df['horsepower'])"
      ],
      "metadata": {
        "id": "EBrR4pzMHQ1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "sns.histplot(df['horsepower'])"
      ],
      "metadata": {
        "id": "mXcgIARJIT21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style(\"darkgrid\")\n",
        "sns.countplot(x = \"origin\", hue='cylinders' ,data = df, palette=\"cubehelix\")"
      ],
      "metadata": {
        "id": "zN9CZ1jDI4BN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6Qq44C6bJHdN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data distribution analysis"
      ],
      "metadata": {
        "id": "1BFovqshi0o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "mo147PVii-to"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['horsepower'])"
      ],
      "metadata": {
        "id": "QI1mdXGYjMSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Correlation analysis"
      ],
      "metadata": {
        "id": "tVDQ-ITRqaTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numcols = df.select_dtypes(include=np.number).columns\n",
        "sns.heatmap(df[numcols].corr(), annot=True, linewidth = 2, cmap = 'Spectral')\n"
      ],
      "metadata": {
        "id": "8AnP7O2zjXQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "RRuWfHs9H2gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from scipy import stats\n",
        "\n",
        "# H0: There is not a correlation.\n",
        "# H1: There is a significant correlation.\n",
        "\n",
        "# Assuming df is your DataFrame and 'col1' and 'col2' are the columns\n",
        "spearman_corr, p_value = stats.spearmanr(df['cylinders'], df['mpg'])\n",
        "\n",
        "print(f\"Spearman Rank Correlation: {spearman_corr}\")\n",
        "print(f\"P-value: {p_value}\")\n",
        "\n",
        "# Hypothesis testing\n",
        "alpha = 0.05  # Or whatever significance level you want\n",
        "if p_value < alpha:\n",
        "    print(\"We reject the null hypothesis and accept the alternative hypothesis. There is a significant correlation.\")\n",
        "else:\n",
        "    print(\"We fail to reject the null hypothesis. There is no significant correlation.\")"
      ],
      "metadata": {
        "id": "h5emlvv6H3SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Linear Regression"
      ],
      "metadata": {
        "id": "61Afo_rkYovO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")\n",
        "df['age'] = 2024 - (1900 + df['model_year'])\n",
        "df.drop(['model_year'], axis = 1, inplace = True)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "TAm-pWsTYrJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# import pandas as pd\n",
        "\n",
        "X = df[['age']]\n",
        "y = df['mpg']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Coefficient: \", model.coef_)"
      ],
      "metadata": {
        "id": "XSLTtvlxYssx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Equation of the model: mpg = {} * age + {}\".format(model.coef_[0], model.intercept_))"
      ],
      "metadata": {
        "id": "AscdSEgPah-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test)"
      ],
      "metadata": {
        "id": "2MccX1wbZxTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate MAE\n",
        "mae_value = mean_absolute_error(y_test, predictions)\n",
        "print(f\"Mean Absolute Error (MAE): {mae_value:.2f}\")\n",
        "\n",
        "# Calculate MSE\n",
        "mse_value = mean_squared_error(y_test, predictions)\n",
        "print(f\"Mean Squared Error (MSE): {mse_value:.2f}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "RMSE = np.sqrt(mse_value)\n",
        "print(\"R Mean Squared Error (RMSE): \", RMSE)\n",
        "\n",
        "# Calculate R2 score\n",
        "r2_value = r2_score(y_test, predictions)\n",
        "print(f\"R-squared (R2) Score: {r2_value:.2f}\")"
      ],
      "metadata": {
        "id": "UVx5hyB7b_jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Linear Regression"
      ],
      "metadata": {
        "id": "8LGT0o_547Ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")\n",
        "df['age'] = 2024 - (1900 + df['model_year'])\n",
        "df.drop(['model_year'], axis = 1, inplace = True)\n",
        "df.dropna(inplace = True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "EvxdWiDP4-GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df[['cylinders', 'displacement', 'horsepower', 'acceleration']]\n",
        "y = df['mpg']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LinearRegression()\n",
        "\n",
        "model.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "damimZhn5CB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(\"Intercept: \", model.intercept_)\n",
        "print(\"Coefficients: \", model.coef_)\n",
        "\n",
        "equation_terms = [\"({:.4f} * {})\".format(coef, feature) for coef, feature in zip(model.coef_, ['cylinders', 'displacement', 'horsepower', 'acceleration'])]\n",
        "equation = \"mpg = \" + \" + \".join(equation_terms) + \" + {:.4f}\".format(model.intercept_)\n",
        "print(\"Model Equation: \", equation)\n"
      ],
      "metadata": {
        "id": "I7gNi99K58HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "lhIRUJj-6ayr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate MAE\n",
        "mae_value = mean_absolute_error(y_test, pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae_value:.2f}\")\n",
        "\n",
        "# Calculate MSE\n",
        "mse_value = mean_squared_error(y_test, pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse_value:.2f}\")\n",
        "\n",
        "# Calculate RMSE\n",
        "RMSE = np.sqrt(mse_value)\n",
        "print(\"R Mean Squared Error (RMSE): \", RMSE)\n",
        "\n",
        "# Calculate R2 score\n",
        "r2_value = r2_score(y_test, pred)\n",
        "print(f\"R-squared (R2) Score: {r2_value:.2f}\")"
      ],
      "metadata": {
        "id": "R8JSXAiM7XY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict(x_test)\n",
        "\n",
        "plt.scatter(x_test['horsepower'], y_test, color='blue', label='Actual data', s=12)\n",
        "\n",
        "plt.scatter(x_test['horsepower'], pred, color='red', label=f'Model predictions {r2_value:.2f}%', s=12)\n",
        "\n",
        "plt.xlabel('horsepower')\n",
        "plt.ylabel('MPG')\n",
        "plt.title('Polynomial Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sq6T39G0TxgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial Regression"
      ],
      "metadata": {
        "id": "P6hLAIyJXoUJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset(\"mpg\")\n",
        "df['age'] = 2024 - (1900 + df['model_year'])\n",
        "df.drop(['model_year'], axis = 1, inplace = True)\n",
        "df.dropna(inplace = True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3NjTBgmMXvxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import PolynomialFeatures\n",
        "# from sklearn.pipeline import make_pipeline\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "\n",
        "x = df[['cylinders', 'displacement', 'horsepower', 'acceleration']]\n",
        "y = df['mpg']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "best_d = 1\n",
        "best_r = -float('inf')\n",
        "for i in range(1, 20):\n",
        "    polynomial_model = make_pipeline(PolynomialFeatures(degree=i), LinearRegression())\n",
        "\n",
        "    polynomial_model.fit(x_train, y_train)\n",
        "\n",
        "    y_pred = polynomial_model.predict(x_test)\n",
        "\n",
        "    r2_value = r2_score(y_test, y_pred)\n",
        "\n",
        "    if r2_value > best_r:\n",
        "        best_d = i\n",
        "        best_r = r2_value\n",
        "\n",
        "print(\"Best degree:\", best_d)"
      ],
      "metadata": {
        "id": "jrUHXrZQYBkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polynomial_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "polynomial_model.fit(x_train, y_train)\n",
        "y_pred = polynomial_model.predict(x_test)"
      ],
      "metadata": {
        "id": "DmkCmfYlaDYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# Calculate MAE\n",
        "mae_value = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Calculate MSE\n",
        "mse_value = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate RMSE\n",
        "RMSE = np.sqrt(mse_value)\n",
        "\n",
        "# Calculate R2 score\n",
        "r2_value = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae_value:.2f}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse_value:.2f}\")\n",
        "print(\"R Mean Squared Error (RMSE): \", RMSE)\n",
        "print(f\"R-squared (R2) Score: {r2_value:.2f}\")"
      ],
      "metadata": {
        "id": "IbDZ3jwgY5LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = polynomial_model.predict(x_test)\n",
        "\n",
        "plt.scatter(x_test['horsepower'], y_test, color='blue', label='Actual data', s=12)\n",
        "\n",
        "plt.scatter(x_test['horsepower'], pred, color='red', label=f'Model predictions {r2_value:.2f}%', s=12)\n",
        "\n",
        "plt.xlabel('horsepower')\n",
        "plt.ylabel('MPG')\n",
        "plt.title('Polynomial Regression Model')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "08m1Fbm54eHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "NPA1EgVz5XzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('iris')\n",
        "print(df.iloc[:, -1].unique())\n",
        "df.dropna(inplace = True)\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "i0stjuaq5abU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map = {'setosa' : 0, 'versicolor' : 1, 'virginica' : 2}\n",
        "df['species'] = df['species'].map(map)\n",
        "\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "-5lN95dM6W4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "colors = ['red', 'green', 'blue']\n",
        "species = df['species'].unique()\n",
        "\n",
        "for specie in species:\n",
        "    subset = df[df['species'] == specie]\n",
        "    plt.scatter(subset['sepal_length'], subset['petal_width'], label=f'Species {specie}', color=colors[specie])\n",
        "\n",
        "plt.title('Scatter Plot of Iris Dataset')\n",
        "plt.xlabel('Sepal Length')\n",
        "plt.ylabel('petal_width')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bgLBdLL57W4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df, hue='species', height = 2.75)"
      ],
      "metadata": {
        "id": "LLSSVZouo8cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Naive Bayes"
      ],
      "metadata": {
        "id": "s9H5us_pB6jq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "x = df[['sepal_length',\t'sepal_width',\t'petal_length',\t'petal_width']]\n",
        "y = df['species']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "gnb = GaussianNB()\n",
        "\n",
        "gnb.fit(x_train, y_train)\n",
        "\n",
        "y_pred = gnb.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "8zblzH7T8swx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-NN"
      ],
      "metadata": {
        "id": "Ttzt3hS9lXn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "x = df[['sepal_length',\t'sepal_width',\t'petal_length',\t'petal_width']]\n",
        "y = df['species']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=12)\n",
        "\n",
        "knn.fit(x_train, y_train)\n",
        "\n",
        "y_pred = knn.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "id": "x5dhzpeiDEun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[100]"
      ],
      "metadata": {
        "id": "Yrgh_hxh1ldJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(knn.predict([df.iloc[100, :-1].values]))\n",
        "print(knn.predict([df.iloc[100, :-1].to_numpy()]))"
      ],
      "metadata": {
        "id": "6o7g4EY61Tsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree"
      ],
      "metadata": {
        "id": "2-p1g27gdk1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "# from sklearn import tree\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "x = df[['sepal_length',\t'sepal_width',\t'petal_length',\t'petal_width']]\n",
        "y = df['species']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "dt = tree.DecisionTreeClassifier()\n",
        "\n",
        "dt.fit(x_train, y_train)\n",
        "\n",
        "y_pred = dt.predict(x_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "id": "e23BRGx01Ygh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 10))\n",
        "tree.plot_tree(dt, filled=True, feature_names=x.columns, class_names=y.unique())\n",
        "plt.title('Decision Tree trained on the dataset')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AcWuG3n_nM2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "W7dJPNkZcgrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "x = df[['sepal_length',\t'sepal_width',\t'petal_length',\t'petal_width']]\n",
        "y = df['species']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators = 3)\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "prediction = model.predict(x_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, prediction))\n",
        "print(classification_report(y_test, prediction))"
      ],
      "metadata": {
        "id": "HzWkYezcckMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "iIX9tWvzflhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "x = df[['sepal_length',\t'sepal_width',\t'petal_length',\t'petal_width']]\n",
        "y = df['species']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "SVC_model = SVC()\n",
        "SVC_model.fit(x_train, y_train)\n",
        "\n",
        "prediction = SVC_model.predict(x_test)\n",
        "\n",
        "print(\"accuracy: \", accuracy_score(y_test, prediction))"
      ],
      "metadata": {
        "id": "Ab13xmZRfp-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics"
      ],
      "metadata": {
        "id": "PLwKjwOj1MT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "conf_m = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(conf_m, annot=True, cmap = \"YlGnBu\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.xlabel(\"Predicted Label\")"
      ],
      "metadata": {
        "id": "ftzPVtiYseDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "tbjKyxbhsx1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## HyperParameter Optimization"
      ],
      "metadata": {
        "id": "4u62muSh-yxb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
        "gs_NB = GridSearchCV(estimator=gnb,\n",
        "                 param_grid=params_NB,\n",
        "                #  cv=cv_method,   # use any cross validation technique\n",
        "                 verbose=1,\n",
        "                 scoring='accuracy')\n",
        "gs_NB.fit(x_train, y_train)\n",
        "\n",
        "gs_NB.best_params_"
      ],
      "metadata": {
        "id": "ZxNudKto-7QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameters to test\n",
        "parameters = {\n",
        "    'n_neighbors' : range(1, 30),\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "# Create grid search instance\n",
        "knn_grid_search = GridSearchCV(estimator = knn,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           return_train_score = True)\n",
        "knn_grid_search.fit(x_train, y_train)\n",
        "\n",
        "knn_grid_search.best_params_"
      ],
      "metadata": {
        "id": "b2UPOg5iFdRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'gamma': [1, 0.1, 0.01],\n",
        "    'kernel': ['poly', 'rbf'],\n",
        "    'degree': range(1, 5)\n",
        "}\n",
        "\n",
        "SVC_model_tuned = GridSearchCV(estimator=SVC_model, param_grid=param_grid)\n",
        "SVC_model_tuned.fit(x_train, y_train)\n",
        "\n",
        "SVC_model_tuned.best_params_\n"
      ],
      "metadata": {
        "id": "JJMuzhd4n0--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-Fold Cross Validation"
      ],
      "metadata": {
        "id": "4b3XkNdQQV5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cvs = cross_val_score(estimator = knn, X = x_train, y = y_train, cv = 10)\n",
        "cvs.mean()"
      ],
      "metadata": {
        "id": "_8zX-VgZdurk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "param_grid = {\n",
        "    'n_neighbors': range(1, 30),  # Example values, adjust as needed\n",
        "    'weights': ['uniform', 'distance'],\n",
        "}\n",
        "\n",
        "# Initialize k-fold cross-validation\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=kf)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "print(\"Best parameters:\", best_params)"
      ],
      "metadata": {
        "id": "5EO94SKQJsDr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I1q6GuHwPAU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering"
      ],
      "metadata": {
        "id": "ESiSSkt6ceBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = sns.load_dataset('iris')\n",
        "print(df.iloc[:, -1].unique())\n",
        "df.dropna(inplace = True)\n",
        "\n",
        "map = {'setosa' : 0, 'versicolor' : 1, 'virginica' : 2}\n",
        "df['species'] = df['species'].map(map)\n",
        "\n",
        "df.sample(5)"
      ],
      "metadata": {
        "id": "RGs6dh2-cgUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hopkins Test"
      ],
      "metadata": {
        "id": "TdHj6A1YEygK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "from random import sample\n",
        "from numpy.random import uniform\n",
        "import numpy as np\n",
        "from math import isnan\n",
        "\n",
        "# Defining the Hopkins test function\n",
        "def hopkins(X):\n",
        "    d = X.shape[1]\n",
        "    #d = len(vars) # columns\n",
        "    n = len(X) # rows\n",
        "    m = int(0.1 * n) # heuristic from article [1]\n",
        "    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n",
        "\n",
        "    rand_X = sample(range(0, n, 1), m)\n",
        "\n",
        "    ujd = []  # distances from random points to their nearest neighbors\n",
        "    wjd = []  # distances from uniformly distributed points to their nearest neighbors\n",
        "\n",
        "    for j in range(0, m):\n",
        "        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n",
        "        ujd.append(u_dist[0][1])\n",
        "        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n",
        "        wjd.append(w_dist[0][1])\n",
        "\n",
        "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
        "    if isnan(H):\n",
        "        print (ujd, wjd)\n",
        "        H = 0\n",
        "\n",
        "    return H\n",
        "\n",
        "hopkins((df))"
      ],
      "metadata": {
        "id": "S-Y6OtzM3pfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "def hopkins_statistic(X, m=0.1):\n",
        "    \"\"\"\n",
        "    Calculate the Hopkins statistic for cluster tendency assessment.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): Input data with shape (n, m).\n",
        "        m (float): Proportion of samples to use for comparison (default is 0.1).\n",
        "\n",
        "    Returns:\n",
        "        float: Hopkins statistic value.\n",
        "    \"\"\"\n",
        "    n, d = X.shape\n",
        "    rand_X = np.random.choice(range(n), size=int(m * n), replace=False)\n",
        "\n",
        "    # Fit nearest neighbors model\n",
        "    nbrs = NearestNeighbors(n_neighbors=2, algorithm='brute').fit(X)\n",
        "\n",
        "    ujd = []  # distances from random points to their nearest neighbors\n",
        "    wjd = []  # distances from uniformly distributed points to their nearest neighbors\n",
        "\n",
        "    for j in range(len(rand_X)):\n",
        "        u_dist, _ = nbrs.kneighbors(np.random.normal(size=(1, d)).reshape(1, -1), 2, return_distance=True)\n",
        "        ujd.append(u_dist[0][1])\n",
        "\n",
        "        w_dist, _ = nbrs.kneighbors(X[rand_X[j]].reshape(1, -1), 2, return_distance=True)\n",
        "        wjd.append(w_dist[0][1])\n",
        "\n",
        "    H = sum(ujd) / (sum(ujd) + sum(wjd))\n",
        "    return H\n",
        "\n",
        "\n",
        "hopkins_value = hopkins_statistic(scale(df))\n",
        "print(f\"Hopkins statistic value: {hopkins_value:.4f}\")"
      ],
      "metadata": {
        "id": "UvVnTrDw8NSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Elbow Method"
      ],
      "metadata": {
        "id": "_KOeR_jSE25Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "rates = []\n",
        "\n",
        "k = range(2, 10)\n",
        "\n",
        "for i in k:\n",
        "   k_means = KMeans(n_clusters = i, random_state = 42)\n",
        "   k_means.fit(df.iloc[:, 0:4])\n",
        "\n",
        "   rates.append(k_means.inertia_)\n",
        "\n",
        "plt.plot(k, rates, \"r\")"
      ],
      "metadata": {
        "id": "ijaOYz9E5a9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_means_yellowbrick = KMeans()\n",
        "graph = KElbowVisualizer(k_means_yellowbrick, k=(2, 10))\n",
        "graph.fit(df.iloc[:, 0:4])\n",
        "graph.poof()"
      ],
      "metadata": {
        "id": "yZA85skR89EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## K-means Clustering"
      ],
      "metadata": {
        "id": "EeV7mQVBE9vi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "k_means = KMeans(n_clusters=3, random_state=42)\n",
        "k_means.fit(df.iloc[:, 0:4])\n",
        "\n",
        "clusters = k_means.labels_\n",
        "clusters"
      ],
      "metadata": {
        "id": "mejLIYIU8svO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import adjusted_rand_score\n",
        "df['clusters'] = clusters\n",
        "\n",
        "adjusted_rand_score(df['species'], df['clusters'])"
      ],
      "metadata": {
        "id": "gvRkg2Zl-0Pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "print(\"Silhouette score for n=4: \", silhouette_score(df.iloc[:, 0:4], df['clusters']))"
      ],
      "metadata": {
        "id": "zieFwEDeDatt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k_means.predict([[4.8,\t4.0,\t4.4,\t4.1]])"
      ],
      "metadata": {
        "id": "btCrorPR3RGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df.iloc[:,1], df.iloc[:,2], c= clusters, s = 50)"
      ],
      "metadata": {
        "id": "zQKMp6kO1i7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df.iloc[:,0:5], hue='species', height= 3)"
      ],
      "metadata": {
        "id": "c-g2-CBU15Jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hierarchical Clustering"
      ],
      "metadata": {
        "id": "Hg8e1S5Rj903"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "example_dataset = make_blobs(n_samples=300, n_features=2, centers=3, cluster_std=1.3, random_state=42)\n",
        "df = pd.DataFrame(columns=['A', \"B\"], data=example_dataset[0])\n",
        "df['C'] = example_dataset[1]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "fP1pYNT4kHDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(df['A'], df['B'])"
      ],
      "metadata": {
        "id": "0xom33XSppFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(df, hue=\"C\", height=2)"
      ],
      "metadata": {
        "id": "0-N3njbWpKpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.cluster.hierarchy as sch\n",
        "dendogram = sch.dendrogram(sch.linkage(df.iloc[:, 0:2], method='ward'))"
      ],
      "metadata": {
        "id": "NiPh7RHOqfYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "hierarchical_clustering_yellowbrick = AgglomerativeClustering()\n",
        "graph = KElbowVisualizer(hierarchical_clustering_yellowbrick, k=(2, 10))\n",
        "graph.fit(df.iloc[:, 0:2])\n",
        "graph.poof()"
      ],
      "metadata": {
        "id": "gFePxQt7uyIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "hierarchical_clustering = AgglomerativeClustering(n_clusters = 3, affinity = \"euclidean\", linkage = \"ward\")\n",
        "\n",
        "y_hier_cluster = hierarchical_clustering.fit(df.iloc[:, 0:2])\n",
        "clusters = y_hier_cluster.labels_\n",
        "clusters"
      ],
      "metadata": {
        "id": "JLcS2OTXrVP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def random_color():\n",
        "    return np.random.rand(3,)\n",
        "\n",
        "for cluster_id in np.unique(clusters):\n",
        "    cluster_points = df[clusters == cluster_id]\n",
        "    plt.scatter(cluster_points['A'], cluster_points['B'], c=random_color(), s=35, label=f\"Cluster {cluster_id}\")\n",
        "\n",
        "plt.xlabel('Feature A')\n",
        "plt.ylabel('Feature B')\n",
        "plt.title('Scatter Plot with Cluster Colors')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0Y4y8DxBt1BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Principal Component Analysis (PCA)"
      ],
      "metadata": {
        "id": "wIcP9MJa2L5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load dataset"
      ],
      "metadata": {
        "id": "hPP96Bae8PBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_digits\n",
        "digits = load_digits()\n",
        "\n",
        "features = digits['data']\n",
        "feature_names = digits[\"feature_names\"]\n",
        "labels = digits['target']\n",
        "\n",
        "df = pd.DataFrame(data = features, columns = feature_names)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "q2bIhcYM2Pxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "KShmTMvT2hL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale the dataset"
      ],
      "metadata": {
        "id": "OuT5cWvF8R2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaled_data = scaler.fit_transform(df)\n",
        "\n",
        "scaled_df = pd.DataFrame(data=scaled_data, columns=feature_names)\n",
        "scaled_df.head()"
      ],
      "metadata": {
        "id": "JX0g9hq-3eE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA With Two Components"
      ],
      "metadata": {
        "id": "aHfI338F8YHs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "vaWJZ2gv51BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=4)"
      ],
      "metadata": {
        "id": "OJ0r1-og-1-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_data = pca.fit_transform(scaled_df)\n",
        "pca_data.shape"
      ],
      "metadata": {
        "id": "WkDwG3fX-_P5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca_data"
      ],
      "metadata": {
        "id": "tGZNW0qD_Qcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "component_df = pd.DataFrame(data = pca_data, columns=[\"first_component\", \"second_component\", \"third_component\", \"fourth_component\"])"
      ],
      "metadata": {
        "id": "Up_TU5AF_RPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "component_df.head()"
      ],
      "metadata": {
        "id": "NJhmOz46_tlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_"
      ],
      "metadata": {
        "id": "l-oftirj_vP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "id": "lAZji4nIAfgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.cumsum(pca.explained_variance_ratio_)"
      ],
      "metadata": {
        "id": "4VKCtB25A1BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender Systems"
      ],
      "metadata": {
        "id": "QPuejHSYLaZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Content Based"
      ],
      "metadata": {
        "id": "fgKqCC0tLgQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Dataset\n",
        "!wget -O moviedataset.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%205/data/moviedataset.zip\n",
        "print('unziping ...')\n",
        "!unzip -o -j moviedataset.zip"
      ],
      "metadata": {
        "id": "-OH_k9ZyLftR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe manipulation library\n",
        "import pandas as pd\n",
        "#Math functions, we'll only need the sqrt function so let's import only that\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "7jJZZoXtLnc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_csv('movies.csv')\n",
        "movies_df.head()"
      ],
      "metadata": {
        "id": "unc7sSx-MDSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using regular expressions to find a year stored between parentheses\n",
        "#We specify the parantheses so we don't conflict with movies that have years in their titles\n",
        "movies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
        "#Removing the parentheses\n",
        "movies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
        "#Removing the years from the 'title' column\n",
        "movies_df['title'] = movies_df.title.str.replace(r'\\s\\(\\d{4}\\)', '', regex=True)\n",
        "#Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
        "movies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\n",
        "movies_df.head()"
      ],
      "metadata": {
        "id": "bgJms1vLO2SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Every genre is separated by a | so we simply have to call the split function on |\n",
        "movies_df['genres'] = movies_df.genres.str.split('|')\n",
        "movies_df.head()"
      ],
      "metadata": {
        "id": "roCM2eWdQj3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Copying the movie dataframe into a new one since we won't need to use the genre information in our first case.\n",
        "moviesWithGenres_df = movies_df.copy()\n",
        "\n",
        "#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column\n",
        "for index, row in movies_df.iterrows():\n",
        "    for genre in row['genres']:\n",
        "        moviesWithGenres_df.at[index, genre] = 1\n",
        "#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre\n",
        "moviesWithGenres_df = moviesWithGenres_df.fillna(0)\n",
        "moviesWithGenres_df.head()"
      ],
      "metadata": {
        "id": "vN_HoLyVUqsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = [\n",
        "            {'title':'Breakfast Club, The', 'rating':5},\n",
        "            {'title':'Toy Story', 'rating':3.5},\n",
        "            {'title':'Jumanji', 'rating':2},\n",
        "            {'title':\"Pulp Fiction\", 'rating':5},\n",
        "            {'title':'Akira', 'rating':4.5}\n",
        "         ]\n",
        "inputMovies = pd.DataFrame(userInput)\n",
        "inputMovies"
      ],
      "metadata": {
        "id": "9MmAvyzqXhZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering out the movies by title\n",
        "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
        "#Then merging it so we can get the movieId. It's implicitly merging it by title.\n",
        "inputMovies = pd.merge(inputId, inputMovies)\n",
        "#Dropping information we won't use from the input dataframe\n",
        "inputMovies = inputMovies.drop(['genres'], axis = 1).drop(['year'], axis = 1)\n",
        "#Final input dataframe\n",
        "#If a movie you added in above isn't here, then it might not be in the original\n",
        "#dataframe or it might spelled differently, please check capitalisation.\n",
        "inputMovies"
      ],
      "metadata": {
        "id": "lgM3eU1jYOxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering out the movies from the input\n",
        "userMovies = moviesWithGenres_df[moviesWithGenres_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
        "userMovies"
      ],
      "metadata": {
        "id": "4DRgVP8-Y3aF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Resetting the index to avoid future issues\n",
        "userMovies = userMovies.reset_index(drop=True)\n",
        "#Dropping unnecessary issues due to save memory and to avoid issues\n",
        "userGenreTable = userMovies.drop(['movieId', 'title', 'genres', 'year'], axis = 1)\n",
        "userGenreTable"
      ],
      "metadata": {
        "id": "JiLh_7_maH-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputMovies['rating']"
      ],
      "metadata": {
        "id": "4ED2yAWWbySr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dot produt to get weights\n",
        "userProfile = userGenreTable.transpose().dot(inputMovies['rating'])\n",
        "#The user profile\n",
        "userProfile"
      ],
      "metadata": {
        "id": "qOPG6NC2axEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now let's get the genres of every movie in our original dataframe\n",
        "genreTable = moviesWithGenres_df.set_index(moviesWithGenres_df['movieId'])\n",
        "#And drop the unnecessary information\n",
        "genreTable = genreTable.drop(['movieId', 'title', 'genres', 'year'], axis = 1)\n",
        "genreTable.head()"
      ],
      "metadata": {
        "id": "CvsEC7SzbqFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiply the genres by the weights and then take the weighted average\n",
        "recommendationTable_df = ((genreTable*userProfile).sum(axis=1))/(userProfile.sum())\n",
        "recommendationTable_df.head()"
      ],
      "metadata": {
        "id": "uWIXp6cIdvd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sort our recommendations in descending order\n",
        "recommendationTable_df = recommendationTable_df.sort_values(ascending=False)\n",
        "#Just a peek at the values\n",
        "recommendationTable_df.head()"
      ],
      "metadata": {
        "id": "i9URxALVepFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The final recommendation table\n",
        "movies_df.loc[movies_df['movieId'].isin(recommendationTable_df.head(20).keys())]"
      ],
      "metadata": {
        "id": "P9dBOEl3ew8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collabrative Filtering"
      ],
      "metadata": {
        "id": "9iqHoiY2iUw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the Dataset\n",
        "!wget -O moviedataset.zip https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-ML0101EN-SkillsNetwork/labs/Module%205/data/moviedataset.zip\n",
        "print('unziping ...')\n",
        "!unzip -o -j moviedataset.zip"
      ],
      "metadata": {
        "id": "t5yHcLtuiYqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataframe manipulation library\n",
        "import pandas as pd\n",
        "#Math functions, we'll only need the sqrt function so let's import only that\n",
        "from math import sqrt\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "YndD1T7eNaEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df = pd.read_csv('movies.csv')\n",
        "ratings_df = pd.read_csv('ratings.csv')\n",
        "movies_df.head()"
      ],
      "metadata": {
        "id": "Xf6PLIrONcKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using regular expressions to find a year stored between parentheses\n",
        "#We specify the parantheses so we don't conflict with movies that have years in their titles\n",
        "movies_df['year'] = movies_df.title.str.extract('(\\(\\d\\d\\d\\d\\))',expand=False)\n",
        "#Removing the parentheses\n",
        "movies_df['year'] = movies_df.year.str.extract('(\\d\\d\\d\\d)',expand=False)\n",
        "#Removing the years from the 'title' column\n",
        "movies_df['title'] = movies_df.title.str.replace(r'\\s\\(\\d{4}\\)', '', regex=True)\n",
        "#Applying the strip function to get rid of any ending whitespace characters that may have appeared\n",
        "movies_df['title'] = movies_df['title'].apply(lambda x: x.strip())\n",
        "movies_df.head()"
      ],
      "metadata": {
        "id": "cM8lgJC-NonK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the genres column\n",
        "movies_df = movies_df.drop(['genres'], axis = 1)"
      ],
      "metadata": {
        "id": "dsIYNN8JOM4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_df.head()"
      ],
      "metadata": {
        "id": "m6I1vpHOOO5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop removes a specified row or column from a dataframe\n",
        "ratings_df = ratings_df.drop('timestamp', axis = 1)"
      ],
      "metadata": {
        "id": "Hno2kJCpOpkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userInput = [\n",
        "            {'title':'Breakfast Club, The', 'rating':5},\n",
        "            {'title':'Toy Story', 'rating':3.5},\n",
        "            {'title':'Jumanji', 'rating':2},\n",
        "            {'title':\"Pulp Fiction\", 'rating':5},\n",
        "            {'title':'Akira', 'rating':4.5}\n",
        "         ]\n",
        "inputMovies = pd.DataFrame(userInput)\n",
        "inputMovies"
      ],
      "metadata": {
        "id": "84rZE76EPIE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering out the movies by title\n",
        "inputId = movies_df[movies_df['title'].isin(inputMovies['title'].tolist())]\n",
        "#Then merging it so we can get the movieId. It's implicitly merging it by title.\n",
        "inputMovies = pd.merge(inputId, inputMovies)\n",
        "#Dropping information we won't use from the input dataframe\n",
        "inputMovies = inputMovies.drop(['year'], axis = 1)\n",
        "#Final input dataframe\n",
        "#If a movie you added in above isn't here, then it might not be in the original\n",
        "#dataframe or it might spelled differently, please check capitalisation.\n",
        "inputMovies"
      ],
      "metadata": {
        "id": "HzwmP1HnP5Vr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Filtering out users that have watched movies that the input has watched and storing it\n",
        "userSubset = ratings_df[ratings_df['movieId'].isin(inputMovies['movieId'].tolist())]\n",
        "userSubset.head()"
      ],
      "metadata": {
        "id": "wd72dQ7EQFKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Groupby creates several sub dataframes where they all have the same value in the column specified as the parameter\n",
        "userSubsetGroup = userSubset.groupby(['userId'])"
      ],
      "metadata": {
        "id": "_3WCltnsROAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userSubsetGroup.get_group(1130)"
      ],
      "metadata": {
        "id": "noBujGbHR77V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sorting it so users with movie most in common with the input will have priority\n",
        "userSubsetGroup = sorted(userSubsetGroup,  key=lambda x: len(x[1]), reverse=True)"
      ],
      "metadata": {
        "id": "7LA0mHBMR-O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userSubsetGroup[0:3]"
      ],
      "metadata": {
        "id": "ylXGHs-sShA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "userSubsetGroup = userSubsetGroup[0:100]"
      ],
      "metadata": {
        "id": "7ZaH-DDcSypj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Store the Pearson Correlation in a dictionary, where the key is the user Id and the value is the coefficient\n",
        "pearsonCorrelationDict = {}\n",
        "\n",
        "#For every user group in our subset\n",
        "for name, group in userSubsetGroup:\n",
        "    #Let's start by sorting the input and current user group so the values aren't mixed up later on\n",
        "    group = group.sort_values(by='movieId')\n",
        "    inputMovies = inputMovies.sort_values(by='movieId')\n",
        "    #Get the N for the formula\n",
        "    nRatings = len(group)\n",
        "    #Get the review scores for the movies that they both have in common\n",
        "    temp_df = inputMovies[inputMovies['movieId'].isin(group['movieId'].tolist())]\n",
        "    #And then store them in a temporary buffer variable in a list format to facilitate future calculations\n",
        "    tempRatingList = temp_df['rating'].tolist()\n",
        "    #Let's also put the current user group reviews in a list format\n",
        "    tempGroupList = group['rating'].tolist()\n",
        "    #Now let's calculate the pearson correlation between two users, so called, x and y\n",
        "    Sxx = sum([i**2 for i in tempRatingList]) - pow(sum(tempRatingList),2)/float(nRatings)\n",
        "    Syy = sum([i**2 for i in tempGroupList]) - pow(sum(tempGroupList),2)/float(nRatings)\n",
        "    Sxy = sum( i*j for i, j in zip(tempRatingList, tempGroupList)) - sum(tempRatingList)*sum(tempGroupList)/float(nRatings)\n",
        "\n",
        "    #If the denominator is different than zero, then divide, else, 0 correlation.\n",
        "    if Sxx != 0 and Syy != 0:\n",
        "        pearsonCorrelationDict[name] = Sxy/sqrt(Sxx*Syy)\n",
        "    else:\n",
        "        pearsonCorrelationDict[name] = 0\n"
      ],
      "metadata": {
        "id": "YRitJIEzTMKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pearsonCorrelationDict"
      ],
      "metadata": {
        "id": "OuGXTcCBTgzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create separate arrays for similarityIndex and userId\n",
        "similarityIndex = list(pearsonCorrelationDict.values())\n",
        "userId = [item[0] for item in pearsonCorrelationDict.keys()]\n",
        "\n",
        "# Create the DataFrame\n",
        "pearsonDF = pd.DataFrame({'similarityIndex': similarityIndex, 'userId': userId})\n",
        "\n",
        "# Display the first few rows\n",
        "pearsonDF.head()\n"
      ],
      "metadata": {
        "id": "pQPPY716Xvcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topUsers=pearsonDF.sort_values(by='similarityIndex', ascending=False)[0:50]\n",
        "topUsers.head()"
      ],
      "metadata": {
        "id": "oNt_PeDeXL7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topUsersRating=topUsers.merge(ratings_df, left_on='userId', right_on='userId', how='inner')\n",
        "topUsersRating.head()"
      ],
      "metadata": {
        "id": "sR47sMJsZqmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Multiplies the similarity by the user's ratings\n",
        "topUsersRating['weightedRating'] = topUsersRating['similarityIndex']*topUsersRating['rating']\n",
        "topUsersRating.head()"
      ],
      "metadata": {
        "id": "Krr0SMp5aPAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Applies a sum to the topUsers after grouping it up by userId\n",
        "tempTopUsersRating = topUsersRating.groupby('movieId').sum()[['similarityIndex','weightedRating']]\n",
        "tempTopUsersRating.columns = ['sum_similarityIndex','sum_weightedRating']\n",
        "tempTopUsersRating.head()"
      ],
      "metadata": {
        "id": "hzpHHXy5bfaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creates an empty dataframe\n",
        "recommendation_df = pd.DataFrame()\n",
        "#Now we take the weighted average\n",
        "recommendation_df['weighted average recommendation score'] = tempTopUsersRating['sum_weightedRating']/tempTopUsersRating['sum_similarityIndex']\n",
        "recommendation_df['movieId'] = tempTopUsersRating.index\n",
        "recommendation_df.head()"
      ],
      "metadata": {
        "id": "YXaiyEDac3Br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommendation_df = recommendation_df.sort_values(by='weighted average recommendation score', ascending=False)\n",
        "recommendation_df.head(10)"
      ],
      "metadata": {
        "id": "b9Qw2jY5d95E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bi6jgdsJeezi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}